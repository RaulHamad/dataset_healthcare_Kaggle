## Espa√±ol: Predicci√≥n de Resultados M√©dicos

# üè• Predicci√≥n de Resultados de Ex√°menes (Kaggle Healthcare Dataset)

Este repositorio contiene un proyecto completo de **Ciencia de Datos**, enfocado en el procesamiento, an√°lisis y modelado de datos del sector salud. El objetivo principal es prever el resultado de ex√°menes de laboratorio (`Test Results`) con base en perfiles de pacientes y condiciones cl√≠nicas.

El proyecto fue estructurado en tres etapas principales, utilizando t√©cnicas experimentales para lidiar con datos de baja correlaci√≥n y alta complejidad.

---

### 1. Limpieza e Ingenier√≠a de Datos (ETL)
**Archivo:** *[Archivo: 01_kaggle_project_cleaning.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/01_kaggle_project_cleaning.ipynb)*

* **Tratamiento:** Eliminaci√≥n de 534 registros duplicados.
* **Codificaci√≥n:** Uso de Label y One-Hot Encoding para datos categ√≥ricos.
* **Escalamiento:** Normalizaci√≥n con `StandardScaler`.

### 2. Benchmark de Modelos y Evaluaci√≥n
**Archivo:** *[Archivo: 02_Kaggle_Classificadores.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/02_Kaggle_Classificadores.ipynb)*

* **Modelos:** Naive Bayes, KNN, √Årboles de Decisi√≥n, Random Forest, Gradient Boosting y MLP.
* **Hallazgo:** Los modelos basados en √°rboles superaron a los lineales.

### 3. Experimentaci√≥n Avanzada y Optimizaci√≥n
**Archivo:** *[Archivo: 03_Modeling_and_Experimentation of Classifiers.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/03_Modeling_and_Experimentation%20of%20Classifiers.ipynb)*

* **Subespacio Aleatorio:** Creaci√≥n de 10 datasets para filtrar "ruido" de atributos.
* **Validaci√≥n:** K-Fold (10 pliegues) para solidez estad√≠stica.
* **Optimizaci√≥n:** **43.81% de precisi√≥n** alcanzado mediante `GridSearchCV`.

![](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/images/grafico.png)

### 4. Escalamiento Sint√©tico y Curva de Aprendizaje (SMOTE)
**Archivo:** *[04_Experimental_Focus.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/04_Experimental_Focus.ipynb)*

Nesta fase, investigamos o impacto do volume de dados na performance dos modelos utilizando o subespa√ßo otimizado de 40% de atributos.

* **Metodologia:** Expans√£o do dataset de 38k para 100k inst√¢ncias utilizando **SMOTE** para gerar dados sint√©ticos e **Resampling** para redu√ß√µes estrat√©gicas.
* **Objetivo:** Identificar o "ponto de satura√ß√£o" onde dados sint√©ticos deixam de ajudar e come√ßam a introduzir ru√≠do.
* **Ponto √ìtimo:** A melhor performance foi atingida com **50.000 inst√¢ncias**, elevando a acur√°cia para **42.03%**.

#### üìà Curva de Aprendizado
O gr√°fico abaixo ilustra a evolu√ß√£o da acur√°cia. Note que ap√≥s as 50k inst√¢ncias, a performance come√ßa a degradar, caracterizando o **Overfitting Sint√©tico**.

![Gr√°fico de Curva de Aprendizado](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/images/04_grafico.png)


---

## English: Test Results Prediction

# üè• Test Results Prediction (Kaggle Healthcare Dataset)

This repository contains a complete **Data Science** project focused on the processing, analysis, and modeling of healthcare sector data. The primary goal is to predict laboratory test results (`Test Results`) based on patient profiles and clinical conditions.

The project was structured into three main stages, utilizing experimental techniques to handle low-correlation and highly complex data.

---

### 1. Cleaning and Data Engineering (ETL)
**File:** *[01_kaggle_project_cleaning.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/01_kaggle_project_cleaning.ipynb)*

* **Data Handling:** Removal of 534 duplicate records.
* **Encoding:** Applied Label and One-Hot Encoding for categorical data.
* **Scaling:** Used `StandardScaler` for numerical normalization.

### 2. Model Benchmark and Evaluation
**File:** *[02_Kaggle_Classificadores.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/02_Kaggle_Classificadores.ipynb)*

* **Tested Models:** Naive Bayes, KNN, Decision Tree, Random Forest, Gradient Boosting, and MLP.
* **Key Finding:** Tree-based models outperformed linear ones, capturing non-linear clinical relationships.

### 3. Advanced Experimentation and Optimization
**File:** *[03_Modeling_and_Experimentation of Classifiers.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/03_Modeling_and_Experimentation%20of%20Classifiers.ipynb)*

* **Random Subspace:** Tested 10 datasets (30-80% density) to reduce noise.
* **Cross-Validation:** 10-fold validation for statistical robustness.
* **Tuning:** Achieved **43.81% accuracy** using `GridSearchCV` with Random Forest.

![](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/images/grafico.png)

### 4. Synthetic Scaling and Learning Curve (SMOTE)
* **File:** *[04_Experimental_Focus.ipynb]*
* **Methodology:** Expanded training set using **SMOTE** to find the saturation point.
* **Result:** Optimal accuracy reached at **50,000 instances (42.03%)**.

  
---

# üè• Predi√ß√£o de Resultados de Exames (Kaggle Healthcare Dataset)

Este reposit√≥rio cont√©m um projeto completo de **Ci√™ncia de Dados**, focado no processamento, an√°lise e modelagem de dados do setor de sa√∫de. O objetivo principal √© prever o resultado de exames laboratoriais (`Test Results`) com base em perfis de pacientes e condi√ß√µes cl√≠nicas.

O projeto foi estruturado em tr√™s etapas principais, utilizando t√©cnicas experimentais para lidar com dados de baixa correla√ß√£o e alta complexidade.

---

## üöÄ Fluxo de Trabalho (Data Science Pipeline)

### 1. Limpeza e Engenharia de Dados (ETL)
**Arquivo:** *[01_kaggle_project_cleaning.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/01_kaggle_project_cleaning.ipynb)*

Nesta etapa inicial, o foco foi transformar dados brutos em um formato otimizado para algoritmos de Machine Learning:
* **Tratamento de Dados:** Identifica√ß√£o e remo√ß√£o de 534 registros duplicados.
* **Codifica√ß√£o de Vari√°veis:** Aplica√ß√£o de **Label Encoding** e **One-Hot Encoding** para converter dados categ√≥ricos (G√™nero, Tipo Sangu√≠neo, Condi√ß√£o M√©dica) em formato num√©rico.
* **Escalonamento:** Uso de `StandardScaler` para normalizar atributos num√©ricos, garantindo que vari√°veis como "Idade" e "Valor da Conta" estejam na mesma escala.
* **Persist√™ncia:** Utiliza√ß√£o da biblioteca **Pickle** para salvar os objetos processados, garantindo a reprodutibilidade entre notebooks.

### 2. Benchmark de Modelos e Avalia√ß√£o
**Arquivo:** *[02_Kaggle_Classificadores.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/02_Kaggle_Classificadores.ipynb)*

Avalia√ß√£o sistem√°tica de m√∫ltiplos algoritmos para estabelecer uma linha de base (baseline):
* **Modelos Testados:** Naive Bayes, KNN, Decision Tree, Random Forest, Gradient Boosting e MLP (Redes Neurais).
* **Metodologia:** Divis√£o treino/teste e an√°lise via **Matriz de Confus√£o** e F1-Score.
* **Descoberta:** Identificamos que modelos baseados em **√°rvores (Random Forest/Decision Tree)** superaram modelos lineares, indicando uma rela√ß√£o n√£o-linear entre os sintomas e os resultados.

### 3. Experimenta√ß√£o Avan√ßada e Otimiza√ß√£o
**Arquivo:** *[03_Modeling_and_Experimentation of Classifiers.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/03_Modeling_and_Experimentation%20of%20Classifiers.ipynb)*

Focada em extrair o m√°ximo de performance atrav√©s de t√©cnicas de pesquisa cient√≠fica:
* **Random Subspace (Subespa√ßo Aleat√≥rio):** Cria√ß√£o de 10 datasets variando a densidade de atributos (de 30% a 80%) para identificar quais colunas geravam "ru√≠do" no modelo.
* **Valida√ß√£o Cruzada (K-Fold):** Uso de 10-folds para garantir que a acur√°cia fosse estatisticamente s√≥lida e n√£o fruto do acaso.
* **Hyperparameter Tuning:** Implementa√ß√£o de `GridSearchCV` para otimizar o Random Forest, alcan√ßando a melhor performance documentada de **43.81% de acur√°cia** (em um cen√°rio desafiador de 3 classes).

![](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/images/grafico.png)

  ### 4. Escalonamento Sint√©tico e Curva de Aprendizado (SMOTE)
**Arquivo:** *[04_Experimental_Focus.ipynb](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/04_Experimental_Focus.ipynb)*
* **Metodologia:** Expans√£o do dataset de 38k para 100k inst√¢ncias via **SMOTE**.
* **Ponto √ìtimo:** A melhor performance foi atingida com **50.000 inst√¢ncias** (acur√°cia de **42.03%**).
* **Insight:** O aumento excessivo (100k) gerou "Overfitting Sint√©tico", degradando a performance.

![Curva de Aprendizado](https://github.com/RaulHamad/dataset_healthcare_Kaggle/blob/main/images/04_grafico.png)

---

